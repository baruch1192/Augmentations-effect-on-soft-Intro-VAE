{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S-IntroVAE_scrypt.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qBs2L72TT_Fv",
        "wVAzhZ762022",
        "8ApROf2GYQ-S",
        "bG2iCeFUdg2y",
        "R9dXuwktZy9P",
        "ZQt7m1MbdHgo",
        "TV83n0NR7qVj",
        "RmpkHJdm72G6",
        "u2xVsE6GZ9Q2",
        "AqO6eO1eaaZM",
        "7SNMsBdfMXyI",
        "oohfgNxsb6Qo",
        "_DfhwdU6b_Bd",
        "JSJe4SY4Sl_f"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anqYZBl93YYz"
      },
      "source": [
        "# Model Performance Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and Installs"
      ],
      "metadata": {
        "id": "qBs2L72TT_Fv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4Qvtz1G8t1w"
      },
      "source": [
        "!pip install kornia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4JQDrFW5B2v"
      },
      "source": [
        "# imports\n",
        "# torch and friends\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.utils as vutils\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets import CIFAR10, MNIST\n",
        "from torchvision import transforms\n",
        "from PIL import Image, ImageOps\n",
        "import kornia.augmentation as K\n",
        "\n",
        "# standard\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "RE5IB0PUUmnn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivqsdceO42wr"
      },
      "source": [
        "def load_model(model, pretrained, device):\n",
        "    weights = torch.load(pretrained, map_location=device)\n",
        "    model.load_state_dict(weights['model'], strict=False)\n",
        "\n",
        "\n",
        "def reparameterize(mu, logvar):\n",
        "    \"\"\"\n",
        "    This function applies the reparameterization trick:\n",
        "    z = mu(X) + sigma(X)^0.5 * epsilon, where epsilon ~ N(0,I)\n",
        "    :param mu: mean of x\n",
        "    :param logvar: log variaance of x\n",
        "    :return z: the sampled latent variable\n",
        "    \"\"\"\n",
        "    device = mu.device\n",
        "    std = torch.exp(0.5 * logvar)\n",
        "    eps = torch.randn_like(std).to(device)\n",
        "    return mu + eps * std\n",
        "\n",
        "\n",
        "def calc_reconstruction_loss(x, recon_x, loss_type='mse', reduction='sum'):\n",
        "    \"\"\"\n",
        "\n",
        "    :param x: original inputs\n",
        "    :param recon_x:  reconstruction of the VAE's input\n",
        "    :param loss_type: \"mse\", \"l1\", \"bce\"\n",
        "    :param reduction: \"sum\", \"mean\", \"none\"\n",
        "    :return: recon_loss\n",
        "    \"\"\"\n",
        "    if reduction not in ['sum', 'mean', 'none']:\n",
        "        raise NotImplementedError\n",
        "    recon_x = recon_x.view(recon_x.size(0), -1)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    if loss_type == 'mse':\n",
        "        recon_error = F.mse_loss(recon_x, x, reduction='none')\n",
        "        recon_error = recon_error.sum(1)\n",
        "        if reduction == 'sum':\n",
        "            recon_error = recon_error.sum()\n",
        "        elif reduction == 'mean':\n",
        "            recon_error = recon_error.mean()\n",
        "    elif loss_type == 'l1':\n",
        "        recon_error = F.l1_loss(recon_x, x, reduction=reduction)\n",
        "    elif loss_type == 'bce':\n",
        "        recon_error = F.binary_cross_entropy(recon_x, x, reduction=reduction)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    return recon_error\n",
        "\n",
        "\n",
        "def interpolate(model, img_1=None, img_2=None, intervals=10, device=\"cpu\"):\n",
        "    if img_1 is not None: # encode\n",
        "        mu, logvar = model.encode(img_1)\n",
        "        z_1 = reparameterize(mu, logvar)\n",
        "    else: # sample z ~ N(0,I)\n",
        "        z_1 = torch.randn(1, model.zdim).to(device)\n",
        "    \n",
        "    if img_2 is not None: # encode\n",
        "        mu, logvar = model.encode(img_2)\n",
        "        z_2 = reparameterize(mu, logvar)\n",
        "    else: # sample z ~ N(0,I)\n",
        "        z_2 = torch.randn(1, model.zdim).to(device)\n",
        "\n",
        "    images = []\n",
        "    for i in range(intervals+1):\n",
        "        t = i / intervals\n",
        "        z = z_1 * (1-t) + z_2 * t\n",
        "        img = model.decode(z)\n",
        "        images.append(img.squeeze(0))\n",
        "    \n",
        "    return images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVAzhZ762022"
      },
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVbb50eO3Tlj"
      },
      "source": [
        "# Building Blocks\n",
        "class GaussianNoise(nn.Module):\n",
        "    def __init__(self, sigma=0.1, is_relative_detach=True):\n",
        "        super(GaussianNoise, self).__init__()\n",
        "        self.sigma = sigma\n",
        "        self.is_relative_detach = is_relative_detach\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.training and self.sigma != 0:\n",
        "            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n",
        "            sampled_noise = torch.normal(mean=torch.zeros_like(x), std=torch.ones_like(x)) * scale\n",
        "            x = x + sampled_noise\n",
        "        return x\n",
        "\n",
        "class AugmentLayers(nn.Module):\n",
        "    def __init__(self, p_augment=0.9):\n",
        "        super(AugmentLayers, self).__init__()\n",
        "        self.p_augment = p_augment\n",
        "        # self.Affine = K.RandomAffine(degrees=0, translate=(1 / 8, 1 / 8), p=p_augment)\n",
        "        self.Erase = K.RandomErasing((0.0, 0.1), p=p_augment)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.Affine(x)\n",
        "        x = self.Erase(x)\n",
        "        return x\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    https://github.com/hhb072/IntroVAE\n",
        "    Difference: self.bn2 on output and not on (output + identity)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, inc=64, outc=64, groups=1, scale=1.0):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        midc = int(outc * scale)\n",
        "\n",
        "        if inc is not outc:\n",
        "            self.conv_expand = nn.Conv2d(in_channels=inc, out_channels=outc, kernel_size=1, stride=1, padding=0,\n",
        "                                         groups=1, bias=False)\n",
        "        else:\n",
        "            self.conv_expand = None\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=inc, out_channels=midc, kernel_size=3, stride=1, padding=1, groups=groups,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(midc)\n",
        "        self.relu1 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.conv2 = nn.Conv2d(in_channels=midc, out_channels=outc, kernel_size=3, stride=1, padding=1, groups=groups,\n",
        "                               bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(outc)\n",
        "        self.relu2 = nn.LeakyReLU(0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.conv_expand is not None:\n",
        "            identity_data = self.conv_expand(x)\n",
        "        else:\n",
        "            identity_data = x\n",
        "        \n",
        "        output = self.relu1(self.bn1(self.conv1(x)))\n",
        "        output = self.conv2(output)\n",
        "        output = self.bn2(output)\n",
        "        output = self.relu2(torch.add(output, identity_data))\n",
        "        return output\n",
        "\n",
        "# Encoder\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, cdim=3, zdim=512, channels=(64, 128, 256, 512, 512, 512), image_size=256, conditional=False,\n",
        "                 cond_dim=10, p_enc_s=0, p_enc_e=0, nn_sigma=0, nn_gn_rel=True, p_augment=0):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.zdim = zdim\n",
        "        self.cdim = cdim\n",
        "        self.image_size = image_size\n",
        "        self.conditional = conditional\n",
        "        self.cond_dim = cond_dim\n",
        "        cc = channels[0]\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(cdim, cc, 5, 1, 2, bias=False),\n",
        "            nn.BatchNorm2d(cc),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.AvgPool2d(2),\n",
        "        )\n",
        "\n",
        "        if p_augment > 0:\n",
        "            print(\"Data augmentation was added\")\n",
        "            self.augment_module = torch.nn.Sequential(\n",
        "                # K.ColorJitter(brightness=(0.7, 1.3), contrast=(0.7, 1.3), saturation=(0.7, 1.3), p=p_augment),\n",
        "                K.RandomAffine(degrees=0, translate=(1 / 8, 1 / 8), p=p_augment),\n",
        "                K.RandomErasing((0.0, 0.5), p=p_augment),\n",
        "            )\n",
        "        else:\n",
        "            self.augment_module = nn.Identity()\n",
        "\n",
        "        gn_i = 0\n",
        "        if nn_sigma > 0:\n",
        "            gn_i += 1\n",
        "            self.main.add_module('GN_{}'.format(gn_i), GaussianNoise(sigma=nn_sigma, is_relative_detach=nn_gn_rel))\n",
        "\n",
        "        if p_enc_s > 0:\n",
        "            print(\"Dropout implemented in the start of the Encoder with value of: \", p_enc_s)\n",
        "            self.main.add_module('dropout_1', nn.Dropout(p_enc_s))\n",
        "        \n",
        "        sz = image_size // 2\n",
        "        for ch in channels[1:]:\n",
        "            self.main.add_module('res_in_{}'.format(sz), ResidualBlock(cc, ch, scale=1.0))\n",
        "            self.main.add_module('down_to_{}'.format(sz // 2), nn.AvgPool2d(2))\n",
        "            cc, sz = ch, sz // 2\n",
        "            if nn_sigma > 0:\n",
        "                gn_i += 1\n",
        "                self.main.add_module('GN_{}'.format(gn_i), GaussianNoise(sigma=nn_sigma, is_relative_detach=nn_gn_rel))\n",
        "\n",
        "\n",
        "        self.main.add_module('res_in_{}'.format(sz), ResidualBlock(cc, cc, scale=1.0))\n",
        "\n",
        "        if nn_sigma > 0:\n",
        "            gn_i += 1\n",
        "            self.main.add_module('GN_{}'.format(gn_i), GaussianNoise(sigma=nn_sigma, is_relative_detach=nn_gn_rel))\n",
        "            print(f\"Gaussian noise added to {gn_i} layers of the encoder with sigma = {nn_sigma}, is_relative_detach={nn_gn_rel}\")\n",
        "\n",
        "        if p_enc_e > 0:\n",
        "            print(\"Dropout implemented in the end of the encoder with value of: \", p_enc_e)\n",
        "            self.main.add_module('dropout_2', nn.Dropout(p_enc_e))\n",
        "\n",
        "        self.conv_output_size = self.calc_conv_output_size()\n",
        "        num_fc_features = torch.zeros(self.conv_output_size).view(-1).shape[0]\n",
        "        # print(\"conv shape: \", self.conv_output_size)\n",
        "        # print(\"num fc features: \", num_fc_features)\n",
        "        if self.conditional:\n",
        "            self.fc = nn.Linear(num_fc_features + self.cond_dim, 2 * zdim)\n",
        "        else:\n",
        "            self.fc = nn.Linear(num_fc_features, 2 * zdim)\n",
        "\n",
        "    def calc_conv_output_size(self):\n",
        "        dummy_input = torch.zeros(1, self.cdim, self.image_size, self.image_size)\n",
        "        dummy_input = self.main(dummy_input)\n",
        "        return dummy_input[0].shape\n",
        "\n",
        "    def forward(self, x, o_cond=None):\n",
        "        if self.training:\n",
        "            x = self.augment_module(x)\n",
        "\n",
        "        y = self.main(x).view(x.size(0), -1)\n",
        "        if self.conditional and o_cond is not None:\n",
        "            y = torch.cat([y, o_cond], dim=1)\n",
        "        y = self.fc(y)\n",
        "        mu, logvar = y.chunk(2, dim=1)\n",
        "        return mu, logvar\n",
        "\n",
        "# Decoder\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, cdim=3, zdim=512, channels=(64, 128, 256, 512, 512, 512), image_size=256, conditional=False,\n",
        "                 conv_input_size=None, cond_dim=10, p_dec_s=0, p_dec_e=0, nn_sigma=0, nn_gn_rel=True):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.cdim = cdim\n",
        "        self.image_size = image_size\n",
        "        self.conditional = conditional\n",
        "        cc = channels[-1]\n",
        "        self.conv_input_size = conv_input_size\n",
        "        if conv_input_size is None:\n",
        "            num_fc_features = cc * 4 * 4\n",
        "        else:\n",
        "            num_fc_features = torch.zeros(self.conv_input_size).view(-1).shape[0]\n",
        "        self.cond_dim = cond_dim\n",
        "        if self.conditional:\n",
        "            self.fc = nn.Sequential(\n",
        "                nn.Linear(zdim + self.cond_dim, num_fc_features),\n",
        "                nn.ReLU(True),\n",
        "            )\n",
        "        else:\n",
        "            self.fc = nn.Sequential(\n",
        "                nn.Linear(zdim, num_fc_features),\n",
        "                nn.ReLU(True),\n",
        "            )\n",
        "\n",
        "        gn_i = 0\n",
        "        if nn_sigma > 0:\n",
        "            gn_i += 1\n",
        "            self.fc.add_module('GN_{}'.format(gn_i), GaussianNoise(sigma=nn_sigma, is_relative_detach=nn_gn_rel))\n",
        "\n",
        "        if p_dec_s > 0:\n",
        "            print(\"Dropout implemented in the start of the Decoder with value of: \", p_dec_s)\n",
        "            self.fc.add_module('dropout_1', nn.Dropout(p_dec_s))\n",
        "        \n",
        "        sz = 4\n",
        "\n",
        "        self.main = nn.Sequential()\n",
        "        for ch in channels[::-1]:\n",
        "            self.main.add_module('res_in_{}'.format(sz), ResidualBlock(cc, ch, scale=1.0))\n",
        "            self.main.add_module('up_to_{}'.format(sz * 2), nn.Upsample(scale_factor=2, mode='nearest'))\n",
        "            cc, sz = ch, sz * 2\n",
        "            if nn_sigma > 0:\n",
        "                gn_i += 1\n",
        "                self.main.add_module('GN_{}'.format(gn_i), GaussianNoise(sigma=nn_sigma, is_relative_detach=nn_gn_rel))\n",
        "\n",
        "        if p_dec_e > 0:\n",
        "            print(\"Dropout implemented in the end of the Decoder with value of: \", p_dec_e)\n",
        "            self.main.add_module('dropout_2', nn.Dropout(p_dec_e))\n",
        "\n",
        "        self.main.add_module('res_in_{}'.format(sz), ResidualBlock(cc, cc, scale=1.0))\n",
        "\n",
        "        if nn_sigma > 0:\n",
        "            gn_i += 1\n",
        "            self.main.add_module('GN_{}'.format(gn_i), GaussianNoise(sigma=nn_sigma, is_relative_detach=nn_gn_rel))\n",
        "            print(f\"Gaussian noise added to {gn_i} layers of the decoder with sigma = {nn_sigma}, is_relative_detach={nn_gn_rel}\")\n",
        "\n",
        "        self.main.add_module('predict', nn.Conv2d(cc, cdim, 5, 1, 2))\n",
        "\n",
        "    def forward(self, z, y_cond=None):\n",
        "        z = z.view(z.size(0), -1)\n",
        "        if self.conditional and y_cond is not None:\n",
        "            y_cond = y_cond.view(y_cond.size(0), -1)\n",
        "            z = torch.cat([z, y_cond], dim=1)\n",
        "        y = self.fc(z)\n",
        "        y = y.view(z.size(0), *self.conv_input_size)\n",
        "        y = self.main(y)\n",
        "        return y\n",
        "\n",
        "# Soft-IntroVAE\n",
        "class SoftIntroVAE(nn.Module):\n",
        "    def __init__(self, cdim=3, zdim=512, channels=(64, 128, 256, 512, 512, 512), image_size=256, conditional=False,\n",
        "                 cond_dim=10, p_enc_s=0, p_enc_e=0, p_dec_s=0, p_dec_e=0, nn_sigma_enc=0, nn_sigma_dec=0, nn_gn_rel=True,\n",
        "                 p_augment=0):\n",
        "        super(SoftIntroVAE, self).__init__()\n",
        "\n",
        "        self.zdim = zdim\n",
        "        self.conditional = conditional\n",
        "        self.cond_dim = cond_dim\n",
        "\n",
        "        self.encoder = Encoder(cdim, zdim, channels, image_size, conditional=conditional, cond_dim=cond_dim,\n",
        "                               p_enc_s=p_enc_s, p_enc_e=p_enc_e, nn_sigma=nn_sigma_enc, nn_gn_rel=nn_gn_rel, p_augment=p_augment)\n",
        "\n",
        "        self.decoder = Decoder(cdim, zdim, channels, image_size, conditional=conditional, conv_input_size=self.encoder.conv_output_size, cond_dim=cond_dim,\n",
        "                               p_dec_s=p_dec_s, p_dec_e=p_dec_e, nn_sigma=nn_sigma_dec, nn_gn_rel=nn_gn_rel)\n",
        "\n",
        "    def forward(self, x, o_cond=None, deterministic=False):\n",
        "        if self.conditional and o_cond is not None:\n",
        "            mu, logvar = self.encode(x, o_cond=o_cond)\n",
        "            if deterministic:\n",
        "                z = mu\n",
        "            else:\n",
        "                z = reparameterize(mu, logvar)\n",
        "            y = self.decode(z, y_cond=o_cond)\n",
        "        else:\n",
        "            mu, logvar = self.encode(x)\n",
        "            if deterministic: \n",
        "                z = mu\n",
        "            else:\n",
        "                z = reparameterize(mu, logvar)\n",
        "            y = self.decode(z)\n",
        "        return mu, logvar, z, y\n",
        "\n",
        "    def sample(self, z, y_cond=None):\n",
        "        y = self.decode(z, y_cond=y_cond)\n",
        "        return y\n",
        "\n",
        "    def sample_with_noise(self, num_samples=1, device=torch.device(\"cpu\"), y_cond=None):\n",
        "        z = torch.randn(num_samples, self.zdim).to(device)\n",
        "        return self.decode(z, y_cond=y_cond)\n",
        "\n",
        "    def encode(self, x, o_cond=None):\n",
        "        if self.conditional and o_cond is not None:\n",
        "            mu, logvar = self.encoder(x, o_cond=o_cond)\n",
        "        else:\n",
        "            mu, logvar = self.encoder(x)\n",
        "        return mu, logvar\n",
        "\n",
        "    def decode(self, z, y_cond=None):\n",
        "        if self.conditional and y_cond is not None:\n",
        "            y = self.decoder(z, y_cond=y_cond)\n",
        "        else:\n",
        "            y = self.decoder(z)\n",
        "        return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abJ5DLe52p7m"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Model"
      ],
      "metadata": {
        "id": "8ApROf2GYQ-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # give notebook access to google drive to load/save checkpoints\n",
        "base_path = './drive/MyDrive/Colab Notebooks/Project B/' # enter path where checkpoint is saved, example: './drive/checkpoints/'\n",
        "# checkpoint = 'cifar10_soft_intro_betas_1.0_256.0_1.0_fid_3.0722174215240443_model_epoch_400_iter_625200.pth' # enter checkpoint name, example: 'cifar10_soft_intro_model_epoch_400.pth'\n",
        "# path = base_path + checkpoint"
      ],
      "metadata": {
        "id": "1ns1NWLvYWGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvbX_6UK5wxx"
      },
      "source": [
        "# Parameters\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "dataset = 'cifar10' # Choose dataset: ['cifar10', 'mnist']\n",
        "\n",
        "\n",
        "z_dim = 128\n",
        "\n",
        "if dataset == 'cifar10':\n",
        "  image_size = 32\n",
        "  channels = [64, 128, 256]\n",
        "  ch = 3\n",
        "  checkpoint      = \"cifar10_soft_intro_betas_1.0_256.0_1.0_fid_2.9929277083944044_model_epoch_660_iter_1031580.pth\" # enter checkpoint name, example: 'cifar10_soft_intro_model_epoch_400.pth'\n",
        "  checkpoint_orig = \"cifar10_soft_intro_betas_1.0_256.0_1.0_fid_3.676469025118422_model_epoch_360_iter_562680.pth\"\n",
        "elif dataset == 'mnist':\n",
        "  image_size = 28\n",
        "  channels = [64, 128]\n",
        "  ch = 1\n",
        "  checkpoint      = \"mnist_soft_intro_betas_1.0_256.0_1.0_model_epoch_450_iter_843750.pth\" # enter checkpoint name, example: 'mnist_soft_intro_model_epoch_400.pth'\n",
        "  checkpoint_orig = \"mnist_orig_soft_intro_betas_1.0_256.0_1.0_model_epoch_400_iter_750000.pth\" # enter checkpoint name, example: 'mnist_soft_intro_orig_model_epoch_400.pth'\n",
        "else:\n",
        "  raise NotImplementedError(\"Dataset is not supported\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load our model\n",
        "model = SoftIntroVAE(cdim=ch, zdim=z_dim, channels=channels, image_size=image_size).to(device)\n",
        "load_model(model, base_path + checkpoint, device)\n",
        "# model.eval()\n",
        "# Load original model for comparison\n",
        "model_orig = SoftIntroVAE(cdim=ch, zdim=z_dim, channels=channels, image_size=image_size).to(device)\n",
        "load_model(model_orig, base_path + checkpoint_orig, device)\n",
        "# model_orig.eval()\n",
        "# Load data\n",
        "if dataset == 'cifar10':\n",
        "    train_data = CIFAR10(root='./cifar10_ds', train=True, download=True, transform=transforms.ToTensor())  \n",
        "    test_data  = CIFAR10(root='./cifar10_ds', train=False, download=True, transform=transforms.ToTensor())  \n",
        "elif dataset == 'mnist':\n",
        "    train_data = MNIST(root='./mnist_ds', train=True, download=True, transform=transforms.ToTensor())  \n",
        "    test_data  = MNIST(root='./mnist_ds', train=False, download=True, transform=transforms.ToTensor())  "
      ],
      "metadata": {
        "id": "jLrjUN2bdhoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Latent Space"
      ],
      "metadata": {
        "id": "R9dXuwktZy9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Latent Map Analysis"
      ],
      "metadata": {
        "id": "ZQt7m1MbdHgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode training data\n",
        "data_loader = DataLoader(train_data, batch_size=1000, shuffle=True, num_workers=2)\n",
        "latent_reps = []\n",
        "labels = []\n",
        "for i, batch in enumerate(data_loader):\n",
        "    batch[0].requires_grad = False\n",
        "    batch[1].requires_grad = False\n",
        "    imgs = batch[0].to(device)\n",
        "    lbls = batch[1]\n",
        "    mu, logvar = model.encode(imgs)\n",
        "    z = reparameterize(mu, logvar)\n",
        "    latent_reps.extend(z.detach().numpy())\n",
        "    labels.extend(lbls.detach().numpy())\n",
        "    if i == 0:\n",
        "        break\n",
        "\n",
        "print(len(latent_reps))\n",
        "latent_reps = np.asarray(latent_reps)\n",
        "print(latent_reps.shape)\n",
        "labels = np.asarray(labels)\n",
        "print(labels.shape)\n",
        "\n",
        "if dataset == 'cifar10':\n",
        "    label_name = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "elif dataset == 'mnist':\n",
        "    label_name = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "\n",
        "color = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']\n",
        "colors = [color[l] for l in labels]\n",
        "\n",
        "# use PCA to vizualize latent representations in 2D\n",
        "map = PCA(n_components=2).fit_transform(latent_reps)\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(7, 7)\n",
        "ax.scatter(map[:, 0], map[:, 1], c=colors, marker='.')\n",
        "ax.set_xlabel(\"PC1\")\n",
        "ax.set_ylabel(\"PC2\")\n",
        "ax.set_title(\"Latent Representation - PCA\")\n",
        "ax.legend()\n",
        "legend_elements = []\n",
        "for i in range(len(label_name)):\n",
        "    legend_elements.append(Line2D([0], [0], color=color[i], label=label_name[i]))\n",
        "ax.legend(handles=legend_elements)\n",
        "plt.show()\n",
        "\n",
        "# use KPCA to vizualize latent representations in 2D\n",
        "map = KernelPCA(n_components=2, kernel='cosine', gamma=1/z_dim).fit_transform(latent_reps)\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(7, 7)\n",
        "ax.scatter(map[:, 0], map[:, 1], c=colors, marker='.')\n",
        "ax.set_xlabel(\"PC1\")\n",
        "ax.set_ylabel(\"PC2\")\n",
        "ax.set_title(\"Latent Representation - KPCA\")\n",
        "ax.legend()\n",
        "legend_elements = []\n",
        "for i in range(len(label_name)):\n",
        "    legend_elements.append(Line2D([0], [0], color=color[i], label=label_name[i]))\n",
        "ax.legend(handles=legend_elements)\n",
        "plt.show()\n",
        "\n",
        "for p in [4, 10, 50, np.sqrt(len(latent_reps))]:\n",
        "# use T-SNE to vizualize latent representations in 2D\n",
        "    map = TSNE(n_components=2, perplexity=p, learning_rate='auto', init='pca').fit_transform(latent_reps)\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(7, 7)\n",
        "    ax.scatter(map[:, 0], map[:, 1], c=colors, marker='.')\n",
        "    ax.set_xlabel(\"Mapped dim1\")\n",
        "    ax.set_ylabel(\"Mapped dim2\")\n",
        "    ax.set_title(\"Latent Representation - TSNE\")\n",
        "    ax.legend()\n",
        "    legend_elements = []\n",
        "    for i in range(len(label_name)):\n",
        "        legend_elements.append(Line2D([0], [0], color=color[i], label=label_name[i]))\n",
        "    ax.legend(handles=legend_elements)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "RoDWoiMmdSr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Interpolation in the Latent Space"
      ],
      "metadata": {
        "id": "TV83n0NR7qVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose source of images to interpolate between: ['trainset', 'testset', 'random', 'cherry']\n",
        "img_src_1 = 'trainset'\n",
        "img_src_2 = 'trainset'\n",
        "\n",
        "# if 'cherry' choose index\n",
        "idx1 = 12012\n",
        "idx2 = 11933\n",
        "\n",
        "train_data_loader = DataLoader(train_data, batch_size=1, shuffle=True, num_workers=1)\n",
        "test_data_loader  = DataLoader(test_data, batch_size=1, shuffle=True, num_workers=1)\n",
        "\n",
        "intervals = 20 # choose number of intervals for linear interpolation"
      ],
      "metadata": {
        "id": "Je429zuRo6vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare image 1\n",
        "if img_src_1 == 'trainset': # take image from train set\n",
        "    img_1 = next(iter(train_data_loader))\n",
        "    img_1 = img_1[0].to(device)\n",
        "\n",
        "elif img_src_1 == 'testset': # take image from test set\n",
        "    img_1 = next(iter(test_data_loader))\n",
        "    img_1 = img_1[0].to(device)\n",
        "\n",
        "elif img_src_1 == 'random': # generate image by sampling z ~ N(0,I)\n",
        "    img_1 = None\n",
        "\n",
        "elif img_src_1 == 'cherry':\n",
        "    img_1 = train_data[idx1][0].unsqueeze(0)\n",
        "\n",
        "else:\n",
        "    raise NotImplementedError(\"Image source is not supported\")\n",
        "\n",
        "# prepare image 1\n",
        "if img_src_2 == 'trainset': # take image from train set\n",
        "    img_2 = next(iter(train_data_loader))\n",
        "    img_2 = img_2[0].to(device)\n",
        "\n",
        "elif img_src_2 == 'testset': # take image from test set\n",
        "    img_2 = next(iter(test_data_loader))\n",
        "    img_2 = img_2[0].to(device)\n",
        "\n",
        "elif img_src_2 == 'random': # generate image by sampling z ~ N(0,I)\n",
        "    img_2 = None\n",
        "\n",
        "elif img_src_2 == 'cherry':\n",
        "    img_2 = train_data[idx2][0].unsqueeze(0)\n",
        "\n",
        "else:\n",
        "    raise NotImplementedError(\"Image source is not supported\")\n",
        "\n",
        "# interpolate\n",
        "images = interpolate(model, img_1, img_2, intervals-1, device)\n",
        "if img_src_1 in ['trainset', 'testset', 'cherry']:\n",
        "    images[0] = img_1.squeeze(0)\n",
        "if img_src_2 in ['trainset', 'testset', 'cherry']:\n",
        "    images[-1] = img_2.squeeze(0)\n",
        "\n",
        "# save images\n",
        "if dataset == 'cifar10':\n",
        "    path = 'figures/cifar10/cifar10_interpolation.jpg'\n",
        "elif dataset == 'mnist':\n",
        "    path = 'figures/mnist/mnist_interpolation.jpg'\n",
        "vutils.save_image(images, base_path + path, nrow=int(intervals/4))\n",
        "\n",
        "# show images\n",
        "to_img = transforms.ToPILImage()\n",
        "fig, axes = plt.subplots(4, int(intervals/4), squeeze=True, figsize=(10, 8))\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    img = to_img(images[i])\n",
        "    ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
        "    ax.imshow(img)"
      ],
      "metadata": {
        "id": "y8wJ3EVX7z3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Latent Space Arithmetic"
      ],
      "metadata": {
        "id": "RmpkHJdm72G6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose source of images: ['trainset', 'testset']\n",
        "img_src = 'trainset'"
      ],
      "metadata": {
        "id": "K0X9gjS38D_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data\n",
        "if img_src == 'trainset':\n",
        "    data = train_data\n",
        "else:\n",
        "    data = test_data\n",
        "data_loader = DataLoader(data, batch_size=3, shuffle=True, num_workers=2)\n",
        "image = next(iter(data_loader))\n",
        "# if dataset == 'cifar10':\n",
        "image = image[0].to(device)\n",
        "\n",
        "# image = torch.empty(3, 3, 32, 32)\n",
        "# for i, idx in enumerate([24543, 48246, 6041]):\n",
        "#     image[i] = train_data[idx][0]\n",
        "\n",
        "# Encode\n",
        "mu, logvar = model.encode(image)\n",
        "z = reparameterize(mu, logvar)\n",
        "# Perform Arithmetic Operation\n",
        "z_new = z[0] - z[1] + z[2]\n",
        "# Decode\n",
        "image_new = model.decode(z_new.unsqueeze(0))\n",
        "images = torch.cat([image, image_new])\n",
        "\n",
        "# Save Images\n",
        "if dataset == 'cifar10':\n",
        "    path = 'figures/cifar10/cifar10_arithmetic.jpg'\n",
        "elif dataset == 'mnist':\n",
        "    path = 'figures/mnist/mnist_arithmetic.jpg'\n",
        "vutils.save_image(images.data.cpu(), base_path + path, nrow=4)\n",
        "\n",
        "# Show Images\n",
        "to_img = transforms.ToPILImage()\n",
        "fig, axes = plt.subplots(1, 4, squeeze=True, figsize=(10, 10))\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    img = to_img(images[i])\n",
        "    ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
        "    ax.imshow(img)"
      ],
      "metadata": {
        "id": "fySWbyBbeFaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generation"
      ],
      "metadata": {
        "id": "u2xVsE6GZ9Q2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Image Generation"
      ],
      "metadata": {
        "id": "AqO6eO1eaaZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "b_size = 14"
      ],
      "metadata": {
        "id": "CAM0LQXiagtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create generated image\n",
        "noise_batch = torch.randn(size=(b_size, z_dim)).to(device)\n",
        "images = model.sample(noise_batch)\n",
        "\n",
        "# Save Images\n",
        "if dataset == 'cifar10':\n",
        "    path = 'figures/cifar10/cifar10_gen.jpg'\n",
        "elif dataset == 'mnist':\n",
        "    path = 'figures/mnist/mnist_gen.jpg'\n",
        "vutils.save_image(images.data.cpu(), base_path + path, nrow=int(b_size/2))\n",
        "\n",
        "# Show Images\n",
        "to_img = transforms.ToPILImage()\n",
        "fig, axes = plt.subplots(2, int(b_size/2), squeeze=True, figsize=(b_size, 4))\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    img = to_img(images[i])\n",
        "    ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
        "    ax.imshow(img)"
      ],
      "metadata": {
        "id": "tr5E-6g1ajt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SNMsBdfMXyI"
      },
      "source": [
        "#### Recurring Encoding Decoding for Generated Image Improvement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWh5A-W9-XRQ"
      },
      "source": [
        "# Parameters\n",
        "b_size = 10\n",
        "num_cycles = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNv0HwJ_QNuq"
      },
      "source": [
        "# Create generated image\n",
        "noise_batch = torch.randn(size=(b_size, z_dim)).to(device)\n",
        "generated_initial = model.sample(noise_batch)\n",
        "\n",
        "# Encode-Decode image for num_cycles\n",
        "generated_rec = generated_initial\n",
        "for i in range(num_cycles):\n",
        "    _, _, _, generated_rec = model(generated_rec)\n",
        "images = torch.cat((generated_initial, generated_rec))\n",
        "\n",
        "# Save Images\n",
        "if dataset == 'cifar10':\n",
        "    path = 'figures/cifar10/cifar10_rec_gen.jpg'\n",
        "elif dataset == 'mnist':\n",
        "    path = 'figures/mnist/mnist_rec_gen.jpg'\n",
        "vutils.save_image(images.data.cpu(), base_path + path, nrow=b_size)\n",
        "\n",
        "# Show Images\n",
        "to_img = transforms.ToPILImage()\n",
        "fig, axes = plt.subplots(2, b_size, squeeze=True, figsize=(2*b_size, 4))\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    img = to_img(images[i])\n",
        "    ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
        "    ax.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reconstruction"
      ],
      "metadata": {
        "id": "oohfgNxsb6Qo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Image Reconstruction"
      ],
      "metadata": {
        "id": "_DfhwdU6b_Bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "b_size = 8\n",
        "\n",
        "# Choose source of images: ['trainset', 'testset']\n",
        "img_src = 'trainset'"
      ],
      "metadata": {
        "id": "T-G5u4rtcD92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data\n",
        "if img_src == 'trainset':\n",
        "    data = train_data\n",
        "else:\n",
        "    data = test_data\n",
        "data_loader = DataLoader(data, batch_size=b_size, shuffle=True, num_workers=2)\n",
        "image = next(iter(data_loader))\n",
        "# if dataset == 'cifar10':\n",
        "image = image[0].to(device)\n",
        "\n",
        "# Reconstruct\n",
        "_, _, _, image_rec = model(image)\n",
        "_, _, _, image_rec_orig = model_orig(image)\n",
        "images = torch.cat((image, image_rec, image_rec_orig))\n",
        "\n",
        "# Save Images\n",
        "if dataset == 'cifar10':\n",
        "    path = 'figures/cifar10/cifar10_rec.jpg'\n",
        "elif dataset == 'mnist':\n",
        "    path = 'figures/mnist/mnist_rec.jpg'\n",
        "vutils.save_image(images.data.cpu(), base_path + path, nrow=b_size)\n",
        "\n",
        "# Show Images\n",
        "to_img = transforms.ToPILImage()\n",
        "fig, axes = plt.subplots(3, b_size, squeeze=True, figsize=(3*b_size, 9))\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    img = to_img(images[i])\n",
        "    ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
        "    ax.imshow(img)"
      ],
      "metadata": {
        "id": "Vkccs2eOca6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSJe4SY4Sl_f"
      },
      "source": [
        "#### Partially Erased Image Reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltAijG69TQJA"
      },
      "source": [
        "# Parameters\n",
        "b_size = 7\n",
        "p_augment = 1\n",
        "num_cycles = 1\n",
        "\n",
        "# Choose source of images: ['trainset', 'testset']\n",
        "img_src = 'trainset'\n",
        "\n",
        "# Choose form of erasing: ['block', 'pixels']\n",
        "erase = 'block'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNtyuYABSk2l"
      },
      "source": [
        "# Prepare data\n",
        "if img_src == 'trainset':\n",
        "    data = train_data\n",
        "else:\n",
        "    data = test_data\n",
        "data_loader = DataLoader(data, batch_size=b_size, shuffle=True, num_workers=2)\n",
        "image = next(iter(data_loader))\n",
        "image = image[0].to(device)\n",
        "\n",
        "# Erase part of image\n",
        "if erase == 'block':\n",
        "    AugModule = AugmentLayers(p_augment)\n",
        "    image_erased = AugModule(image)\n",
        "elif erase == 'pixels':\n",
        "    zero_indices = torch.randint(low=0, high=image_size, size=(image.shape[0], int(0.2*np.square(image.shape[2])), 2))\n",
        "    mask = torch.ones_like(image)\n",
        "    for n in range(image.shape[0]):\n",
        "        for i, j in zero_indices[n]:\n",
        "            mask[n, :, i, j] = 0\n",
        "    image_erased = image * mask\n",
        "else:\n",
        "    raise NotImplementedError(\"Method is not supported\")\n",
        "\n",
        "# Reconstruct\n",
        "image_rec = image_erased\n",
        "image_rec_orig = image_erased\n",
        "\n",
        "for i in range(num_cycles):\n",
        "  _, _, _, image_rec = model(image_rec)\n",
        "  _, _, _, image_rec_orig = model_orig(image_rec_orig)\n",
        "\n",
        "images = torch.cat((image, image_erased, image_rec_orig, image_rec))\n",
        "\n",
        "# Save Images\n",
        "if dataset == 'cifar10':\n",
        "    path = 'figures/cifar10/cifar10_erased_rec.jpg'\n",
        "elif dataset == 'mnist':\n",
        "    path = 'figures/mnist/mnist_erased_rec.jpg'\n",
        "vutils.save_image(images.data.cpu(), base_path + path, nrow=b_size)\n",
        "\n",
        "# Show Images\n",
        "to_img = transforms.ToPILImage()\n",
        "fig, axes = plt.subplots(4, b_size, squeeze=True, figsize=(2*b_size, 8))\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    img = to_img(images[i])\n",
        "    ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
        "    ax.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}